{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bab810e",
   "metadata": {},
   "source": [
    "# CE - 652\n",
    "## Artificial Intelligence for Autonomous Driving\n",
    "## Application Assignments \n",
    "##### Week: 9\n",
    "##### Instructor: Dr. Juan D. Gomez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625326f",
   "metadata": {},
   "source": [
    "####  Excercise1:\n",
    "\n",
    "Please create a simple code in python to have a simple chat with chatGPT from within this Jupyter notebook using the OpenAI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b56c3",
   "metadata": {},
   "source": [
    "In the previous example, we connected to OpenAI's API since the LLM runs in the cloud. However, alternative LLMs, such as DeepSeek, provide similar cloud-based inference while also offering downloadable models that can be deployed locally.\n",
    "\n",
    "This tutorial demonstrates how to use DeepSeek in the same manner as ChatGPT above, but with the advantage of a free API key:\n",
    "\n",
    "TUTORIAL 1: [How to Use DeepSeek API for Free: A Step-by-Step Guide](https://apidog.com/blog/how-to-use-deepseek-api-for-free/) \n",
    "\n",
    "Additionally, this tutorial covers running DeepSeek locally on your machine, leveraging LangChain and Retrieval-Augmented Generation (RAG) for enhanced contextual responses:\n",
    "\n",
    "TUTORIAL 2: [Setting DeepSeek Locally](https://dev.to/ajmal_hasan/setting-up-ollama-running-deepseek-r1-locally-for-a-powerful-rag-system-4pd4)\n",
    "\n",
    "You are encouraged to experiment with either approach or both and report your experience with DeepSeek here (i.e., the same chat you previously had with chatGPT) . However, be aware that the local deployment requires significant hardware resources, which most of you may not have. Nevertheless, feel free to attempt the local setup if you have the necessary computational capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
